{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf0344e-2247-46b9-ba20-ff452b8644c5",
   "metadata": {},
   "source": [
    "# Cover Page \n",
    "### Student ID: 210003508\n",
    "### Module Code: GG4257 \n",
    "### Module Title: Urban Analytics: A Toolkit for Sustainable Urban Development\n",
    "### Assignment: Lab Assignment No 2 - Networks, Geodemographics and Spatial Microsimulation.\n",
    "### Degree Programme: Geography \n",
    "### Deadline Date: 02.04.2025\n",
    "\n",
    "In submitting this assignment, I hereby confirm that:\n",
    "\n",
    "I have read the University's statement on Good Academic Practice; that the following work is my own work; and that significant academic debts and borrowings have been properly acknowledged and referenced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b50b2-f778-4014-9ac2-2bb4e4c839ce",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This section outlines how to replicate the code and access the required data. All data will be available in a **OneDrive folder**, with the code provided in a dedicated GitHub repository.\n",
    "\n",
    "This report documents the work conducted for **Lab Assignment 2**, covering challenges from **Labs 5, 6 and 7**. Each lab section includes problem descriptions, methods, and results. Code is supplemented with comments and markdown explanations, with screenshots of outputs (e.g., maps and graphs) included to ensure clarity and help replication. To meet GitHub size limits, certain output cells have been cleared from the notebook. All data paths in the code assume files are stored in a folder named \"Data\". \n",
    "\n",
    "#### GitHub Username: Ejarrettt\n",
    "#### GitHub Repository: [UA_Lab_Assignment_2](https://github.com/ejarrettt/UA_Lab_Assignment_2)\n",
    "#### [OneDrive Folder](https://1drv.ms/f/c/46775ff05561cd60/EtpKCVLnUXtMupoCXG5G86QB-GfpojgYMR0f4hgJI-Fclg?e=bvGWOb)\n",
    "\n",
    "To replicate this report:\n",
    "1. Clone the GitHub repository.\n",
    "2. Download the datasets from the [OneDrive Folder](https://1drv.ms/f/c/46775ff05561cd60/EtpKCVLnUXtMupoCXG5G86QB-GfpojgYMR0f4hgJI-Fclg?e=bvGWOb).\n",
    "3. Unzip the folder and copy the \"Data\" folder to the same place you have stored the notebook. \n",
    "4. Run this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f8c55-cb26-4059-9518-1b18cb76912c",
   "metadata": {},
   "source": [
    "# Lab No 5: Introduction to Networks (2 Challenges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f84e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Install dependencies for all the Labs \n",
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa65102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Lab 5\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nxviz as nv\n",
    "import osmnx as ox\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c164b-da19-40b4-ba0a-a95c2b893b1d",
   "metadata": {},
   "source": [
    "## Challenge 1:\n",
    "\n",
    "It's time for you to apply everything you learned by analyzing a case study of FourSquare social Network. (Foursquare is a location-based online social network. The dataset contains a list of all of the user-to-user links)\n",
    "\n",
    "Datasource: @inproceedings{gao2012exploring,\n",
    "     title={Exploring social-historical ties on location-based social networks},\n",
    "     author={Gao, Huiji and Tang, Jiliang and Liu, Huan},\n",
    "     booktitle={Proceedings of the 6th International AAAI Conference on Weblogs and Social Media},\n",
    "     year={2012}\n",
    "}\n",
    "\n",
    "- **Data**: `FS.csv` (avaliable in Moodle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849fccd2",
   "metadata": {},
   "source": [
    "### Q1. Read the FS network dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a6972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Foursquare social network dataset into Pandas DataFrame\n",
    "fs_network = pd.read_csv(\"/Users/elenajarrett/Library/CloudStorage/OneDrive-Personal/Year 4/GG4257/Data2/Data/data5/FS.csv\")\n",
    "\n",
    "# Print column names to check data structure\n",
    "print(fs_network.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a NetworkX graph from the dataset\n",
    "G = nx.from_pandas_edgelist(fs_network, source='source', target='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5b2d9",
   "metadata": {},
   "source": [
    "### Q2. Describe using the basic functions of the graph's size. Explore nodes and edges. Provide how many nodes and edges are present in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d493ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic properties of the network\n",
    "print(f\"The size of the graph is: {len(G)}\") # Total number of nodes\n",
    "print(f\"The number of edges in the graph is: {len(G.edges())}\") # Number of connections\n",
    "print(f\"The number of nodes in the graph is: {len(G.nodes())}\") # Number of users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d926f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore graph properties\n",
    "print(type(G.nodes()))  # Check the type of the nodes list\n",
    "print(list(G.edges(data=True))[-1])  # Display attributes of the last edge\n",
    "print(list(G.nodes(data=True))[0])  # Display attributes of the first node\n",
    "print(type(list(G.edges(data=True))[-1][2]))  # Confirm attribute data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf823a",
   "metadata": {},
   "source": [
    "### Q3. The dataset generates a graph of 639.014 nodes, so it is massive and you won't see anything meaningful if you try to plot it. So you need to create a subset using the **degree centrality** to find out find the top 4 of the most important nodes, and use them to create a subset of the original network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9d633-4c00-4f13-b7d1-4d7b80c13b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.number_of_selfloops(G)\n",
    "# There are no self-loops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9257651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute degree centrality for all nodes\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Get the top 4 nodes with highest degree centrality\n",
    "top_4_nodes = sorted(degree_centrality, key=degree_centrality.get, reverse=True)[:4]\n",
    "print(\"Top 4 nodes with highest degree centrality:\", top_4_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c5a5d-1a41-4772-888b-a158ff542803",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_from_G=G.edges([106223, 89302, 76517, 66999], data=True) #Give me the edges where only 106223 etc. are nodes.\n",
    "edges_from_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66883f8f-b14b-41dd-b884-664e2e73ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sub = nx.DiGraph()\n",
    "len(G_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6247a55-270e-4976-8990-a78073dff780",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sub.add_edges_from(edges_from_G) #Adding the list from the subset of nodes.\n",
    "len(G_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb54b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edges involving the top 4 nodes\n",
    "edges_from_G = G.edges(top_4_nodes)\n",
    "\n",
    "# Create a directed subgraph for the most important nodes\n",
    "G_sub = nx.DiGraph()\n",
    "G_sub.add_edges_from(edges_from_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subgraph of top 4 nodes and their neighbours\n",
    "nbunch = set(top_4_nodes)  # Start with top 4 nodes\n",
    "for node in top_4_nodes:\n",
    "    nbunch.update(G.neighbors(node))  # Add their neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subgraph\n",
    "subG = G.subgraph(nbunch).copy()  # Copy to prevent changes affecting the original graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic info\n",
    "print(f\"Subgraph has {subG.number_of_nodes()} nodes and {subG.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subgraph with ONLY the top 4 most important nodes\n",
    "subG_top4 = G.subgraph(top_4_nodes).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806d116",
   "metadata": {},
   "source": [
    "### Q4. Extract the degree centrality values and convert them into a list. Then, plot a histogram to visualize the distribution of node degrees in the original network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa0cad-32f6-4164-9275-3527c8cc30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract degree centrality values and convert them into a list\n",
    "centrality_list = list(degree_centrality.values())\n",
    "\n",
    "# Print the first 10 values for reference\n",
    "print(centrality_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ed6a2-4fec-44d0-b8b2-ddaf26287c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram to visualize the distribution of degree centrality\n",
    "plt.hist(centrality_list, bins=10, edgecolor=\"black\")\n",
    "plt.xlabel(\"Degree Centrality\")\n",
    "plt.ylabel(\"Number of Nodes\")\n",
    "plt.title(\"Distribution of Node Degrees\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b326c",
   "metadata": {},
   "source": [
    "### Q5. Create a plot for the subset created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85097cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise and plot the top 4 nodes subgraph\n",
    "plt.figure(figsize=(6, 6))\n",
    "pos = nx.spring_layout(subG_top4, seed=42) \n",
    "nx.draw(subG_top4, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=8)\n",
    "plt.title(\"Subgraph of Only the Top 4 Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the full subgraph (Top 4 nodes + neighbours)\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw(G_sub, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe17db",
   "metadata": {},
   "source": [
    "### Q6. Now calculate another relevant measure of the network -- **betweenness centrality**. Plot the betweenness centrality distribution of the subset you created. Tip: Same steps from the previous step, but use `nx.betweenness_centrality()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f886c-39de-487f-8dc8-0e140c09b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty graph to store the network subset\n",
    "G_network_subset = nx.Graph()\n",
    "# Add edges from the extracted subgraph to the new graph\n",
    "G_network_subset.add_edges_from(subG_top4.edges())\n",
    "\n",
    "# Compute betweenness centrality for all nodes in the subset graph\n",
    "betweenness_centrality = nx.betweenness_centrality(G_network_subset)\n",
    "\n",
    "# Convert the betweenness centrality values into a list for analysis\n",
    "betweenness_list = list(betweenness_centrality.values())\n",
    "\n",
    "# Print the degree centrality list\n",
    "#print(betweenness_list) # This outcome is quite long, as a note. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee69b1-fbca-4728-b355-9e25205c9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram to visualize the distribution of betweenness centrality\n",
    "plt.hist(betweenness_list, bins=5) \n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel(\"Betweenness Centrality\")\n",
    "plt.ylabel(\"Number of Nodes\")\n",
    "plt.title(\"Distribution of Betweenness Centrality\")\n",
    "\n",
    "# Plot the histogram \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b50d6-8737-42bb-812b-3937a65a746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty graph for visualization\n",
    "git_network_subset = nx.Graph()\n",
    "\n",
    "# Add edges from the subset graph correctly\n",
    "git_network_subset.add_edges_from(subG_top4.edges())  # Extract edges before adding\n",
    "\n",
    "# Compute betweenness centrality for the visualization graph\n",
    "betweenness_centrality = nx.betweenness_centrality(git_network_subset)\n",
    "\n",
    "# Generate node positions for better visualization\n",
    "pos = nx.spring_layout(git_network_subset, seed=42)\n",
    "\n",
    "# Draw the graph with node labels and customized appearance\n",
    "nx.draw(\n",
    "    git_network_subset, \n",
    "    pos, \n",
    "    with_labels=True, \n",
    "    node_size=700,  # Set node size for better visibility\n",
    "    node_color='skyblue'  # Use a distinct color for contrast\n",
    ")\n",
    "\n",
    "# Add a title to the graph visualization\n",
    "plt.title(\"Graph Representation of Subset with Betweenness Centrality\")\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6930f5",
   "metadata": {},
   "source": [
    "### Q7. Plot the Matrix, Arc and Circos from the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency Matrix Plot\n",
    "nv.MatrixPlot(subG_top4)\n",
    "plt.title(\"Adjacency Matrix of Subgraph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0092354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arc Diagram\n",
    "nv.ArcPlot(subG_top4)\n",
    "plt.title(\"Arc Diagram of Subgraph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10998a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circos Plot\n",
    "nv.CircosPlot(subG_top4)\n",
    "plt.title(\"Circos Plot of Subgraph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d833a-e725-46d1-b7df-4746bc8ac3ff",
   "metadata": {},
   "source": [
    "## Challenge 2: \n",
    "\n",
    "This challenge is about OSMnx. You will explore and analyze a city's street network using the OSMnx Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9fe65",
   "metadata": {},
   "source": [
    "### Q1. Use OSMnx to download the street network of a city of your choice. You can specify the city name, BBox or a Dict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18be425",
   "metadata": {},
   "source": [
    "First, I download the street network of Birmngham, focusing on New Street Station as the central point. The OSMnx library is then used to retrieve the drivable street network of Birmingham within a 2-mile radius of the central point. The function `graph_from_point()` is used with a \"drive\" filter to extract only the roads meant for vehicular traffic. After retrieving the network, we visualize it using `ox.plot_graph()`, with no node markers for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82fae25-3716-4a10-85ba-31d5c66edcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the central point of Birmingham (New Street Station) and a 2-mile search radius\n",
    "birmingham_centre = (52.4778, -1.8984)\n",
    "two_miles = 3218.68  # Distance in meters \n",
    "\n",
    "# Retrieve the street network for drivable roads within the defined radius using Bounding Box method \n",
    "G_birmingham = ox.graph_from_point(birmingham_centre, dist=two_miles, network_type=\"drive\")\n",
    "\n",
    "# Plot and visualise the street network\n",
    "fig, ax = ox.plot_graph(G_birmingham, node_size=0, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion the street network graph to a GDF (nodes and edges)\n",
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G_birmingham)\n",
    "# Now, `gdf_nodes` contains information about intersections and endpoints,\n",
    "# and `gdf_edges` contains information about streets and their attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f19a66",
   "metadata": {},
   "source": [
    "### Q2. Calculate basic statistics for the street network, such as the number of nodes, edges, average node degree, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be8c4d",
   "metadata": {},
   "source": [
    "To analyse the network, we project the graph, compute the area and calculate statitstics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the area in meters of the map \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Project the graph to a coordinate reference system (CRS) with metric units instead of degrees\n",
    "G_birmingham_proj = ox.project_graph(G_birmingham)\n",
    "\n",
    "# Extract the nodes from the projected graph as a GeoDataFrame\n",
    "nodes_proj = ox.graph_to_gdfs(G_birmingham_proj, edges=False)\n",
    "\n",
    "# Calculate the convex hull area of the network in square meters\n",
    "graph_area_m = nodes_proj.unary_union.convex_hull.area\n",
    "\n",
    "# Print the result \n",
    "print(f\"Graph Area (mÂ²): {graph_area_m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic statistics of the map such as number of nodes, edges, intersection density, etc.\n",
    "basic_stats = ox.basic_stats(G_birmingham_proj, area=graph_area_m, clean_int_tol=15)\n",
    "print(\"Basic Statistics of the Street Network:\")\n",
    "basic_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441426c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .edges/.nodes and len() to explicity print the number of nodes and edges \n",
    "num_edges = len(list(G_birmingham.edges))\n",
    "num_nodes = len(list(G_birmingham.nodes))\n",
    "\n",
    "print(f\"Number of edges: {num_edges}\")\n",
    "print(f\"Number of nodes: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1583de6",
   "metadata": {},
   "source": [
    "### Q3. Use OSMnx to plot the street network. Customize the plot to make it visually appealing, including node size, edge color. See the potential options here: https://osmnx.readthedocs.io/en/stable/user-reference.html#module-osmnx.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customising and plotting the street network of Birmingham using matplotlib\n",
    "fig, ax = ox.plot_graph(G_birmingham,\n",
    "                         figsize=(10, 10),  \n",
    "                         node_size=4,  \n",
    "                         edge_color=\"red\",  \n",
    "                         edge_linewidth=0.5,  \n",
    "                         show=False)  \n",
    "\n",
    "# Add a title \n",
    "plt.title(\"Street Network around Birmingham New Street Station Within Two Miles\") \n",
    "\n",
    "# Display the plot \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6148dd",
   "metadata": {},
   "source": [
    "I have also created another plot with different customisation. Edges are colored based on their length using the \"plasma\" colormap. Nodes are colored based on their degree centrality (number of connected streets) using the \"viridis\" colormap. The background is set to black for improved contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af42520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate edge colors based on their length attribute\n",
    "edge_colors = ox.plot.get_edge_colors_by_attr(G_birmingham, attr=\"length\", cmap=\"plasma\", start=0, stop=1)\n",
    "\n",
    "# Generate node colors based on degree centrality (connectivity)\n",
    "node_colors = ox.plot.get_node_colors_by_attr(G_birmingham, attr=\"street_count\", cmap=\"viridis\", start=0, stop=1)\n",
    "\n",
    "# Customise and plot the street network with node and edge attributes using osmnx.plot\n",
    "fig, ax = ox.plot.plot_graph(\n",
    "    G_birmingham,\n",
    "    figsize=(10, 10),  \n",
    "    node_size=10,  \n",
    "    node_color=node_colors,  # Color nodes based on connectivity\n",
    "    edge_color=edge_colors,  # Color edges based on length\n",
    "    edge_linewidth=0.8, \n",
    "    bgcolor=\"black\",  \n",
    "    show=False,\n",
    ")\n",
    "\n",
    "# Add a title with styling\n",
    "plt.title(\"Street Network around Birmingham New Street Station (2-Mile Radius)\", fontsize=14, color=\"white\", pad=20)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d888b",
   "metadata": {},
   "source": [
    "### Q4. Utilize the routing capabilities of OSMnx to find the shortest path between two points in the street network. Plot the route on top of the street network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda68f0",
   "metadata": {},
   "source": [
    "The routing process begins by estimating road speeds using `ox.speed.add_edge_speeds(G_birmingham)` and calculating travel times for each road segment with `ox.speed.add_edge_travel_times(G_birmingham)`. The nearest network nodes to Birmingham New Street Station and Aston University are identified using `ox.distance.nearest_nodes()`, and the shortest path, minimizing travel time, is computed with `ox.shortest_path()`. The route is visualized using `ox.plot_graph_route()`, highlighted in yellow with thicker lines for clarity. Distance calculations include the total route length (sum of edge lengths along the path) and the great-circle (haversine) distance, which measures the straight-line distance between the two points. Comparing these distances helps assess the efficiency of the road network by highlighting deviations between direct and real-world travel routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimated speeds and travel times to edges\n",
    "G_birmingham = ox.speed.add_edge_speeds(G_birmingham)\n",
    "G_birmingham = ox.speed.add_edge_travel_times(G_birmingham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the nearest street network nodes to two selected lat/long points (origin and destination) using the distance module\n",
    "orig = ox.distance.nearest_nodes(G_birmingham, X=-1.8984, Y=52.4778)  # Birmingham New Street Station\n",
    "dest = ox.distance.nearest_nodes(G_birmingham, X=-1.8881, Y=52.4862)  # Aston University\n",
    "\n",
    "# Print the result \n",
    "print(f\"Origin Node: {orig}, Destination Node: {dest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa13eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the shortest route based on travel time \n",
    "route = ox.shortest_path(G_birmingham, orig, dest, weight=\"travel_time\")\n",
    "\n",
    "# Plot the shortest route on top of the street network \n",
    "fig, ax = ox.plot_graph_route(G_birmingham, route, node_size=0, route_color=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82355926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total route distance in meters \n",
    "# Extract edge lengths along the route and sum them\n",
    "edge_lengths = ox.utils_graph.route_to_gdf(G_birmingham, route)[\"length\"]\n",
    "route_distance_m = round(sum(edge_lengths))\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total route distance (meters): {route_distance_m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the great-circle distance (haversine) between origin and destination \n",
    "# # Get the coordinates of the origin and destination nodes\n",
    "orig_x = G_birmingham.nodes[orig][\"x\"]\n",
    "orig_y = G_birmingham.nodes[orig][\"y\"]\n",
    "dest_x = G_birmingham.nodes[dest][\"x\"]\n",
    "dest_y = G_birmingham.nodes[dest][\"y\"]\n",
    "\n",
    "# Calculate great-circle distance (haversine)\n",
    "haversine_distance_m = round(ox.distance.great_circle(orig_y, orig_x, dest_y, dest_x))\n",
    "\n",
    "#Â Print the results\n",
    "print(f\"Great-circle (haversine) distance (meters) between Birmingham New Street Station and Aston University: {haversine_distance_m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040a46a-c2d2-4506-8264-506a52b51be9",
   "metadata": {},
   "source": [
    "COULD DO ELEVATION???? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58452f",
   "metadata": {},
   "source": [
    "### Q5. Calculate the centrality measures (e.g., degree centrality and betweenness_centrality) for nodes in the street network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c922e",
   "metadata": {},
   "source": [
    "Centrality measures help assess the importance of nodes and edges in a network. In this analysis, we compute **degree centrality, betweenness centrality, and closeness centrality** for both edges and nodes in Birminghamâs street network. **Closeness centrality**, which indicates how easily a node or edge can access the entire network, is computed by converting the street network to a **line graph** (where edges become nodes) and visualizing the results using a color-coded plot. **Betweenness centrality**, which measures how often an edge appears on the shortest paths between node pairs, is also computed through a **line graph transformation** and visualized based on its values. Similarly, **degree centrality**, which represents the number of direct connections a node (or edge) has, is calculated and displayed using a different colormap. For node-level centrality, we directly compute and store **degree, betweenness, and closeness centrality** as node attributes in the original graph. To effectively visualize these measures, we use `ox.plot_graph()` with different colormaps: **Inferno for betweenness centrality**, highlighting frequently used nodes, **Plasma for degree centrality**, identifying highly connected nodes, and **Viridis for closeness centrality**, showing nodes with the shortest average path to others. This analysis helps in identifying **the most connected, frequently used, and strategically positioned streets** in Birminghamâs road network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149eeb0",
   "metadata": {},
   "source": [
    "REMOVE AS NOT WHAT QUESTION IS ASKING! \n",
    "\n",
    "First, I calculate closeness centrality on Edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph to a line graph (edges become nodes and vice versa)\n",
    "edge_centrality = nx.closeness_centrality(nx.line_graph(G_birmingham))\n",
    "\n",
    "# Store the centrality values as edge attributes in the original graph\n",
    "nx.set_edge_attributes(G_birmingham, edge_centrality, \"edge_centrality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate edge colors based on closeness centrality values\n",
    "ec = ox.plot.get_edge_colors_by_attr(G_birmingham, \"edge_centrality\", cmap=\"inferno\")\n",
    "\n",
    "# Plot the graph with edges colored based on closeness centrality\n",
    "fig, ax = ox.plot_graph(G_birmingham, edge_color=ec, edge_linewidth=2, node_size=0, show=False)\n",
    "\n",
    "# Add a title \n",
    "ax.set_title(\"Closeness Centrality of Birmingham Street Network (Edges)\", fontsize=14, pad=20, color=\"black\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39831e",
   "metadata": {},
   "source": [
    "Next, I compute Betweenness Centrality on Edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a205b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate betweenness centrality for edges using a line graph transformation and store in a dictionary\n",
    "betweenness_centrality = nx.betweenness_centrality(G_birmingham)\n",
    "\n",
    "# Extracting betweenness_centrality values as a list\n",
    "betweenness_list = list(betweenness_centrality.values())\n",
    "\n",
    "# Print the betweeness centrality list (this is not ran as it is very long)\n",
    "#Â print(betweenness_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12febc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph to line graph so edges become nodes and vice versa\n",
    "betweenness_centrality = nx.betweenness_centrality(nx.line_graph(G_birmingham))\n",
    "\n",
    "# Store the centrality values as edge attributes\n",
    "nx.set_edge_attributes(G_birmingham, betweenness_centrality, \"betweenness_centrality\")\n",
    "\n",
    "# Generate edge colors based on betweenness centrality\n",
    "ec = ox.plot.get_edge_colors_by_attr(G_birmingham, \"betweenness_centrality\", cmap=\"inferno\")\n",
    "\n",
    "# Plot the graph with edges colored based on betweenness centrality\n",
    "fig, ax = ox.plot_graph(G_birmingham, edge_color=ec, edge_linewidth=2, node_size=0, show=False)\n",
    "\n",
    "# Add a title \n",
    "ax.set_title(\"Betweenness Centrality of Birmingham Street Network (Edges)\", fontsize=14, pad=20, color=\"black\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f20ab3",
   "metadata": {},
   "source": [
    "Finally, I calculate the Degree Centrality for Edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773017c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degree centrality for edges using a line graph transformation and store in a dictionary\n",
    "degree_centrality = nx.degree_centrality(G_birmingham)\n",
    "\n",
    "# Extracting degree centrality values as a list\n",
    "centrality_list = list(degree_centrality.values())\n",
    "\n",
    "# Print the degree centrality list (this is not ran as it is very long)\n",
    "#Â print(centrality_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d24949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph to line graph so edges become nodes and vice versa\n",
    "degree_centrality = nx.degree_centrality(nx.line_graph(G_birmingham))\n",
    "\n",
    "# Store the centrality values as edge attributes\n",
    "nx.set_edge_attributes(G_birmingham, degree_centrality, \"degree_centrality\")\n",
    "\n",
    "# Colour the edges in original graph with degree centralities from line graph\n",
    "ec = ox.plot.get_edge_colors_by_attr(G_birmingham, \"degree_centrality\", cmap=\"inferno\")\n",
    "\n",
    "# Plot the graph with edges colored based on betweenness centrality\n",
    "fig, ax = ox.plot_graph(G_birmingham, edge_color=ec, edge_linewidth=2, node_size=0, show=False)\n",
    "\n",
    "# Add a title \n",
    "ax.set_title(\"Degree Centrality of Birmingham Street Network (Edges)\", fontsize=14, pad=20, color=\"black\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e5782",
   "metadata": {},
   "source": [
    "#### Closeness Centrality for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506eb09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate closeness centrality for each node in the graph\n",
    "node_closeness_centrality = nx.closeness_centrality(G_birmingham)\n",
    "\n",
    "# Store the computed centrality values as node attributes in the graph\n",
    "nx.set_node_attributes(G_birmingham, node_closeness_centrality, \"node_closeness_centrality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d15f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node colors based on their closeness centrality values \n",
    "nc = ox.plot.get_node_colors_by_attr(G_birmingham, \"node_closeness_centrality\", cmap=\"inferno\")\n",
    "\n",
    "# Plot the graph with nodes colored based on their closeness centrality\n",
    "fig, ax = ox.plot_graph(G_birmingham, node_color=nc, node_size=20, edge_linewidth=0.5, show=False)\n",
    "\n",
    "# Add a title \n",
    "ax.set_title(\"Closeness Centrality of Birmingham Street Network (Nodes)\", fontsize=14, pad=20, color=\"black\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05a9f5",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate betweenness centrality for each node in the graph\n",
    "node_betweenness_centrality = nx.betweenness_centrality(G_birmingham)\n",
    "\n",
    "# Store the computed centrality values as node attributes in the graph\n",
    "nx.set_node_attributes(G_birmingham, node_betweenness_centrality, \"node_betweenness_centrality\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node colors based on their betweenness centrality values \n",
    "nc = ox.plot.get_node_colors_by_attr(G_birmingham, \"node_betweenness_centrality\", cmap=\"inferno\")\n",
    "\n",
    "# Plot the graph with nodes colored based on their betweenness centrality\n",
    "fig, ax = ox.plot_graph(G_birmingham, node_color=nc, node_size=20, edge_linewidth=0.5, show=False)\n",
    "\n",
    "# Add a title \n",
    "ax.set_title(\"Betweenness Centrality of Birmingham Street Network (Nodes)\", fontsize=14, pad=20, color=\"black\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e2d82",
   "metadata": {},
   "source": [
    "#### Degree Centrality for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degree centrality for each node in the graph\n",
    "nodes_degree_centrality = nx.degree_centrality(G_birmingham)\n",
    "\n",
    "# Store the computed centrality values as node attributes in the graph\n",
    "nx.set_node_attributes(G_birmingham, nodes_degree_centrality, \"nodes_degree_centrality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node colors based on their degree centrality values using the \"plasma\" colormap\n",
    "nc = ox.plot.get_node_colors_by_attr(G_birmingham, \"nodes_degree_centrality\", cmap=\"plasma\")\n",
    "\n",
    "# Plot the graph with nodes colored based on their degree centrality\n",
    "fig, ax = ox.plot_graph(G_birmingham, node_color=nc, node_size=20, edge_linewidth=0.5, show=False)\n",
    "\n",
    "# Add a title \n",
    "ax.set_title(\"Degree Centrality of Birmingham Street Network (Nodes)\", fontsize=14, pad=20, color=\"black\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b90d26",
   "metadata": {},
   "source": [
    "### Q6. Create the figure-ground from the selected city\n",
    "\n",
    "A figure-ground diagram is a visual representation of the urban structure, highlighting streets while leaving the background as empty space. This technique helps to analyse the connectivity and density of an urban area.\n",
    "\n",
    "In this task, I generated figure-ground diagrams for two locations in Birmingham (New Street Station and the Jewellery Quarter). \n",
    "\n",
    "I use OSMnx's plot_figure_ground() function to extract street networks for both areas, customize the figure aesthetics, and save the outputs as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Configure image display settings \n",
    "img_folder = \"images\"\n",
    "extension = \"png\"\n",
    "size = 300\n",
    "dpi = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288dbf8e",
   "metadata": {},
   "source": [
    "#### Figure-ground for New Street Station in Birmingham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b070f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location (Birmingham New Street Station)\n",
    "place = \"Birmingham New Street Station\"\n",
    "point = (52.4778, -1.8984) # Lat and Long coordinates \n",
    "\n",
    "# Define street widths based on road types\n",
    "street_widths = {\n",
    "    \"footway\": 0.5,\n",
    "    \"steps\": 0.5,\n",
    "    \"pedestrian\": 0.5,\n",
    "    \"path\": 0.5,\n",
    "    \"track\": 0.5,\n",
    "    \"service\": 2,\n",
    "    \"residential\": 3,\n",
    "    \"primary\": 5,\n",
    "    \"motorway\": 6,\n",
    "}\n",
    "\n",
    "# Define file path for saving the image\n",
    "fp = f\"./{img_folder}/{place}.{extension}\"\n",
    "\n",
    "# Create a Matplotlib figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Set a black background for better contrast\n",
    "fig.patch.set_facecolor(\"black\")\n",
    "ax.set_facecolor(\"black\")\n",
    "\n",
    "# Create the figure-ground diagram \n",
    "ox.plot_figure_ground(\n",
    "    point=point,\n",
    "    network_type=\"all\",\n",
    "    street_widths=street_widths,\n",
    "    ax=ax,  # Use the predefined Matplotlib axis\n",
    "    save=False,  # Prevent automatic saving\n",
    "    show=False,  # Prevent automatic display\n",
    ")\n",
    "\n",
    "# Add a title to the plot\n",
    "ax.set_title(\n",
    "    f\"Figure-Ground Diagram: {place}\", \n",
    "    fontsize=16, \n",
    "    fontweight=\"bold\", \n",
    "    color=\"white\",  \n",
    "    pad=15\n",
    ")\n",
    "\n",
    "# Remove axis labels for a clean visualisation\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Save the image\n",
    "plt.savefig(fp, dpi=dpi, bbox_inches=\"tight\", facecolor=\"black\")\n",
    "\n",
    "# Close the plot to prevent redundant output in Jupyter\n",
    "plt.close(fig)\n",
    "\n",
    "# Display the saved image\n",
    "Image(fp, height=size, width=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c7843",
   "metadata": {},
   "source": [
    "#### Figure-ground for the Jewellery Quarter in Birmingham "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is the same as above but the location has changed \n",
    "# Define new area in Birmingham - Jewellery Quarter\n",
    "place = \"Birmingham Jewellery Quarter\"\n",
    "point = (52.4862, -1.9134)  \n",
    "\n",
    "# Define street widths based on road types\n",
    "street_widths = {\n",
    "    \"footway\": 0.5,\n",
    "    \"steps\": 0.5,\n",
    "    \"pedestrian\": 0.5,\n",
    "    \"path\": 0.5,\n",
    "    \"track\": 0.5,\n",
    "    \"service\": 2,\n",
    "    \"residential\": 3,\n",
    "    \"primary\": 5,\n",
    "    \"motorway\": 6,\n",
    "}\n",
    "\n",
    "# Define file path for saving the image\n",
    "fp = f\"./{img_folder}/{place}.{extension}\"\n",
    "\n",
    "# Create a Matplotlib figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Set a black background for better contrast\n",
    "fig.patch.set_facecolor(\"black\")\n",
    "ax.set_facecolor(\"black\")\n",
    "\n",
    "# Create the figure-ground diagram \n",
    "ox.plot_figure_ground(\n",
    "    point=point,\n",
    "    network_type=\"all\",\n",
    "    street_widths=street_widths,\n",
    "    ax=ax,  \n",
    "    save=False,  \n",
    "    show=False, \n",
    ")\n",
    "\n",
    "# Add a title to the plot\n",
    "ax.set_title(\n",
    "    f\"Figure-Ground Diagram: {place}\", \n",
    "    fontsize=16, \n",
    "    fontweight=\"bold\", \n",
    "    color=\"white\",  # Title color set to white\n",
    "    pad=15\n",
    ")\n",
    "\n",
    "# Remove axis labels for a clean visualisation\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Save the image\n",
    "plt.savefig(fp, dpi=dpi, bbox_inches=\"tight\", facecolor=\"black\")\n",
    "\n",
    "# Close the plot to prevent redundant output in Jupyter\n",
    "plt.close(fig)\n",
    "\n",
    "# Display the saved image\n",
    "Image(fp, height=size, width=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891d431",
   "metadata": {},
   "source": [
    "### Q7. Create interactive maps to plot nodes, edges, nodes and edges and one of the centrality measures.\n",
    "\n",
    "Interactive maps provide a dynamic way to explore Birminghamâs street network. In this task, we first visualize nodes and edges separately to examine their individual structures. Next, we overlay nodes and edges in a single interactive map for a comprehensive view of the network. To enhance understanding of road distribution, edges are colored based on their length, highlighting variations in street segments. Additionally, nodes are color-coded according to betweenness centrality, allowing us to identify key intersections that play a crucial role in connectivity. These visualizations are generated using the folium-based `.explore()` function, which enables interactive exploration with different basemap styles.\n",
    "\n",
    "#### Interactive Map of Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87256c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph to a GeoDataFrame of nodes\n",
    "nodes = ox.graph_to_gdfs(G_birmingham, edges=False)\n",
    "\n",
    "# Create an interactive map of nodes using the \"CartoDB Positron\" basemap\n",
    "nodes.explore(tiles=\"cartodbpositron\", marker_kwds={\"radius\": 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0f9d7",
   "metadata": {},
   "source": [
    "#### Interactive Map of Graph Edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d93c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph to a GeoDataFrame of edges and explore them interactively\n",
    "ox.graph_to_gdfs(G_birmingham, nodes=False).explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c86b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore edges interactively, colored by their length\n",
    "edges.explore(tiles=\"cartodbdarkmatter\", column=\"length\", cmap=\"plasma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885ecb7",
   "metadata": {},
   "source": [
    "#### Interactive Map of Nodes and Edges Combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db11583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph into separate GeoDataFrames for nodes and edges\n",
    "nodes, edges = ox.graph_to_gdfs(G_birmingham)\n",
    "\n",
    "# Create an interactive map of edges first\n",
    "m = edges.explore(color=\"skyblue\", tiles=\"cartodbdarkmatter\")\n",
    "\n",
    "# Overlay nodes on the same map in yellow\n",
    "nodes.explore(m=m, color=\"yellow\", marker_kwds={\"radius\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b588ffd",
   "metadata": {},
   "source": [
    "#### Interactive Map of Nodes Colored by Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73dacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute betweenness centrality for nodes (weighted by road length)\n",
    "nx.set_node_attributes(G_birmingham, nx.betweenness_centrality(G_birmingham, weight=\"length\"), name=\"bc\")\n",
    "\n",
    "# Convert the graph to a GeoDataFrame of nodes with the centrality attribute\n",
    "nodes = ox.graph_to_gdfs(G_birmingham, edges=False)\n",
    "\n",
    "# Create an interactive map of nodes colored by betweenness centrality\n",
    "nodes.explore(tiles=\"cartodbpositron\", column=\"bc\", marker_kwds={\"radius\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4699de8",
   "metadata": {},
   "source": [
    "### Q8. Export the street network to a GeoPackage (.gpkg) file. Ensure that the exported file contains both node and edge attributes. Demonstrate that the new GeoPackage can be used and read in Python using any of the libraries we have seen in the class to create a simple and interactive map.\n",
    "\n",
    "A **GeoPackage (.gpkg)** is a widely used GIS format that stores spatial data in a single, portable file. In this task, we first export the **Birmingham street network** as a GeoPackage, ensuring that both node and edge attributes are preserved. Next, we read the exported file back into Python using **GeoPandas**, allowing us to verify and manipulate the data within a Python environment. Finally, we visualize the network interactively by mapping both **nodes and edges** on a single interactive map, enabling dynamic exploration of the street network. This process ensures that the exported network remains compatible with **GIS software** such as **QGIS and ArcGIS**, while also being seamlessly integrated into Python workflows for further spatial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5822fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the street network to a GeoPackage file for use in GIS and Python\n",
    "ox.save_graph_geopackage(G_birmingham, filepath=\"data/birminghamnetwork.gpkg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the GeoPackage file back into Python as GeoDataFrames\n",
    "gdf_nodes, gdf_edges = gpd.read_file(\"data/birminghamnetwork.gpkg\", layer=\"nodes\"), gpd.read_file(\"data/birminghamnetwork.gpkg\", layer=\"edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4da107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive map to demonstrate that the GeoPackage has been successfully read into Python\n",
    "# Visualise the edges from the GeoPackage\n",
    "m = gdf_edges.explore(color=\"red\", tiles=\"cartodbdarkmatter\")\n",
    "\n",
    "# Overlay nodes onto the same interactive map to show full network connectivity\n",
    "gdf_nodes.explore(m=m, color=\"skyblue\", marker_kwds={\"radius\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08461f58",
   "metadata": {},
   "source": [
    "### Q9. Finally, use OSMnx to extract other urban elements (e.g., buildings, parks) and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bcf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore deprecation warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "# Extract all building footprints within a 2-mile radius of previously defined centre \n",
    "building_footprints = ox.geometries_from_point(\n",
    "    birmingham_centre,\n",
    "    tags={\"building\": True},\n",
    "    dist=two_miles,\n",
    ")\n",
    "\n",
    "# Extract road network for driving\n",
    "G_birmingham = ox.graph_from_point(\n",
    "    birmingham_centre, \n",
    "    dist=two_miles, \n",
    "    network_type=\"drive\"\n",
    ")\n",
    "\n",
    "# Extract Railway Network (subway, light rail, tram and rail)\n",
    "G_rail = ox.graph_from_point(\n",
    "    birmingham_centre, \n",
    "    dist=two_miles, \n",
    "    network_type=\"all\", \n",
    "    custom_filter='[\"railway\"~\"subway|light_rail|tram|rail\"]'\n",
    ")\n",
    "\n",
    "# Extract parks and greenspaces\n",
    "parks = ox.geometries_from_point(\n",
    "    birmingham_centre,\n",
    "    tags={\"leisure\": \"park\"},\n",
    "    dist=two_miles,\n",
    ")\n",
    "\n",
    "# Extract cycleways\n",
    "cycleways = ox.graph_from_point(\n",
    "    birmingham_centre, \n",
    "    dist=two_miles, \n",
    "    network_type=\"all\", \n",
    "    custom_filter='[\"highway\"~\"cycleway\"]'\n",
    ")\n",
    "\n",
    "# Create a Figure with a black background\n",
    "fig, ax = plt.subplots(figsize=(12, 10), facecolor=\"black\")\n",
    "ax.set_facecolor(\"black\") \n",
    "\n",
    "# Plot road network in light gray\n",
    "ox.plot_graph(G_birmingham, ax=ax, node_size=0, edge_color=\"lightgray\", edge_linewidth=0.5, show=False)\n",
    "\n",
    "# Plot railway network in red\n",
    "ox.plot_graph(G_rail, ax=ax, node_size=0, edge_color=\"red\", edge_linewidth=1.0, show=False)\n",
    "\n",
    "# Plot cycleways in blue\n",
    "ox.plot_graph(cycleways, ax=ax, node_size=0, edge_color=\"blue\", edge_linewidth=1.2, show=False)\n",
    "\n",
    "# Plot building footprints in yellow\n",
    "building_footprints.plot(ax=ax, facecolor=\"yellow\", edgecolor=\"none\", alpha=0.8)\n",
    "\n",
    "# Plot greenspaces in green\n",
    "parks.plot(ax=ax, facecolor=\"green\", edgecolor=\"none\", alpha=0.6)\n",
    "\n",
    "# Add Title \n",
    "ax.set_title(\"Birmingham City Centre: Roads, Railways, Cycleways, Parks, and Buildings\", fontsize=16, fontweight=\"bold\", color=\"white\", pad=15)\n",
    "\n",
    "# Show final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ed1eb",
   "metadata": {},
   "source": [
    "WHAT ARE THE BLUE DOTS? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccfc008-d07d-451f-86e8-e4edb053599c",
   "metadata": {},
   "source": [
    "# Lab No 6: Geodemographics (1 Challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries for Lab 6\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeec99d-a5cc-4e2e-b6e6-e10e38fc51b9",
   "metadata": {},
   "source": [
    "## Challenge 1: Geodemographic Classification\n",
    "\n",
    "In this challenge, you will replicate the process of creating a geodemographic classification using the k-means clustering algorithm. Please select any city in the UK except London, Liverpool, or Glasgow. The main goal is to generate a meaningful and informative classification that captures the diversity of areas in your dataset using the census data ( For England, you can try to use the 2021 or 2011 census, and for Scotland, you need to use the 2011 census data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19a368",
   "metadata": {},
   "source": [
    "### Q1. Define the main goal for the geodemographic classification (marketing, retail and service planning). \n",
    "\n",
    "The goal of this project is to support retail planning in Birmingham. By classifying neighbourhoods based on demographic and socio-economic variables, businesses can better understand local markets, strategically place stores, and target consumers more effectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba5d84e",
   "metadata": {},
   "source": [
    "### Q2. Look for census data from the selected city for which you would like to generate the geodemographic classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f3f9a",
   "metadata": {},
   "source": [
    "I will use 2021 Census Data for England t the Output Area (OA) level, accessed via [NOMIS](https://www.nomisweb.co.uk/sources/census_2021_bulk). Each CSV file contains a set of variables which will be merged into a single dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755beef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_directory = \"/Users/elenajarrett/Library/CloudStorage/OneDrive-Personal/Year 4/GG4257/Data2/Data/data6/census_raw_data/\"\n",
    "\n",
    "# Get a list list of all the CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(csv_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Add an empty DataFrame to store the merged data\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file - read and mege them column wise\n",
    "for csv_file in csv_files:\n",
    "    csv_path = os.path.join(csv_directory, csv_file) # We create a consistent path\n",
    "    df_csv = pd.read_csv(csv_path, low_memory=False) #read each file\n",
    "    # Concatenate/Merge all columns, there is a pitfall here, you will get a duplicate oa_code from all csv files.\n",
    "    merged_data = pd.concat([merged_data, df_csv], axis=1)\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_data.to_csv(\"/Users/elenajarrett/Library/CloudStorage/OneDrive-Personal/Year 4/GG4257/Data2/Data/data6/census_raw_data/merged_census_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c971f",
   "metadata": {},
   "source": [
    "Additionally, I found the [output area classification shapefile](https://data.cdrc.ac.uk/dataset/output-area-classification-2011#data-and-resources) for the  UK. I also used local planning authority (LPA) boundaries from a previously used shapefile from Lab No 2 to help define Birmingham's boundary. \n",
    "\n",
    "CHANGE LAB NO 2 TO SOURCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UK LPAs and filter for Birmingham \n",
    "UK_LPA = \"/Users/elenajarrett/Library/CloudStorage/OneDrive-Personal/Year 4/GG4257/Data2/Data/data6/LAP_2021/LPA_MAY_2021_UK_BUC_V2.shp\" \n",
    "gdf_UK_LPA = gpd.read_file(UK_LPA) \n",
    "birmingham_lpa_gdf = gdf_UK_LPA[gdf_UK_LPA.LPA21NM == \"Birmingham LPA\"] \n",
    "\n",
    "# Define the output areas in UK and clip to Birmingham boundary \n",
    "oa_shapefile = gpd.read_file(\"/Users/elenajarrett/Library/CloudStorage/OneDrive-Personal/Year 4/GG4257/Data2/Data/data6/2011_OAC.shp\")\n",
    "birmingham_oa = gpd.clip(oa_shapefile, birmingham_lpa_gdf)\n",
    "\n",
    "# Save the results \n",
    "birmingham_oa.to_file(\"/Users/elenajarrett/Library/CloudStorage/OneDrive-Personal/Year 4/GG4257/Data2/Data/data6/birmingham_oa.shp\", driver='ESRI Shapefile') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d673b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datasets structure \n",
    "birmingham_oa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mege the census data to Birmingham Output Area Shapefile by mating the OA code \n",
    "csv_path = \"/Users/elenajarrett/Library/CloudStorage/OneDrive-Personal/Year 4/GG4257/Data2/Data/data6/census_raw_data/merged_census_data.csv\"\n",
    "csv_data = pd.read_csv(csv_path, low_memory=False)\n",
    "merged_data = birmingham_oa.merge(csv_data, left_on='OA_SA', right_on='geography code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new dataset \n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbc1ef",
   "metadata": {},
   "source": [
    "### Q3. The census data at the Output Area OA level. Select multiple topics of at least four topics (socio-demographics, economics, health, and so on). Describe your topic selection accordingly based on the goal of your geodemographic classification. For example, if your geodemographics are related to marketing, Economic variables might be the appropriate selection. \n",
    "\n",
    "To develop a robust geodemographic classification, we have selected variables from four key domains that collectively capture demographic structure, economic activity, health status, and living conditions. These dimensions are critical in understanding spatial variations in population characteristics and their implications for consumer behavior, service provision, and urban planning.  \n",
    "\n",
    "##### **Selected Topics and Justification**  \n",
    "1. **Socio-Demographics**  \n",
    "   - Variables: Age distribution, household composition, ethnicity, migration patterns  \n",
    "   - *Justification*: These factors shape community structures, social needs, and cultural diversity, influencing patterns of service demand and market segmentation.  \n",
    "\n",
    "2. **Economics**  \n",
    "   - Variables: Employment status, occupation types, income levels  \n",
    "   - *Justification*: Economic stability and workforce composition determine purchasing power, economic resilience, and access to financial resources, which are crucial for geodemographic analysis.  \n",
    "\n",
    "3. **Health**  \n",
    "   - Variables: General health status, disability prevalence  \n",
    "   - *Justification*: Health indicators reflect the well-being of communities and can influence service provision, healthcare accessibility, and local policy decisions.  \n",
    "\n",
    "4. **Housing & Living Conditions**  \n",
    "   - Variables: Housing tenure, overcrowding, access to essential services  \n",
    "   - *Justification*: Housing stability and living conditions impact quality of life, neighborhood desirability, and long-term socio-economic outcomes.  \n",
    "\n",
    "##### **Selected 2021 Census Datasets**  \n",
    "To operationalise these topics, we will utilize the following census datasets:  \n",
    "\n",
    "- **Population & Demographics**  \n",
    "  - **TS001**: Number of usual residents in households and communal establishments  \n",
    "  - **TS006**: Population density  \n",
    "  - **TS008**: Sex distribution  \n",
    "  - **TS007A**: Age by five-year age bands  \n",
    "\n",
    "- **Economic Activity**  \n",
    "  - **TS058**: Distance travelled to work (mobility patterns)  \n",
    "  - **TS063**: Occupation types (workforce distribution)  \n",
    "  - **TS066**: Economic activity status (employment/unemployment levels)  \n",
    "  - **TS067**: Highest level of qualification (educational attainment)  \n",
    "  - **TS068**: Schoolchildren and full-time students (education participation)  \n",
    "\n",
    "- **Health & Well-being**  \n",
    "  - **TS037**: General health (self-reported health status)  \n",
    "  - **TS038**: Disability prevalence (long-term illness or disability)  \n",
    "\n",
    "- **Housing & Living Conditions**  \n",
    "  - **TS011**: Households by deprivation dimensions (multi-dimensional deprivation indicators)  \n",
    "  - **TS021**: Ethnic group (diversity & integration)  \n",
    "  - **TS029**: Proficiency in English (language barriers & social inclusion)  \n",
    "  - **TS041**: Number of households (housing stock and population distribution)  \n",
    "  - **TS054**: Tenure (owner-occupied vs. rental market trends)  \n",
    "\n",
    "##### **Relevance to Geodemographic Classification**  \n",
    "These datasets provide a multi-faceted understanding of population characteristics, economic conditions, and residential patterns. By integrating these variables, we can classify geographical areas into meaningful segments, helping policymakers, businesses, and urban planners tailor services and interventions to meet the diverse needs of different communities.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75921381",
   "metadata": {},
   "source": [
    "### Q4. Identify the variables that will be crucial for effectively segmenting neighbourhoods. Evaluate how this choice may impact the classification results, including a DEA analysis.\n",
    "\n",
    "Key variables chosen for clustering:\n",
    "   - **Socio-demographics**: Percentage of young (0-18), working-age (18-64), and elderly (65+)\n",
    "   - **Economics**: Unemployment rate, percentage of professionals vs. manual laborers\n",
    "   - **Health**: Percentage reporting âbadâ or âvery badâ health\n",
    "   - **Housing**: Percentage of households in social housing, percentage of owner-occupied homes\n",
    "\n",
    "Impact Analysis:\n",
    "   - A high percentage of young people may indicate demand for educational services and youth-oriented retail.\n",
    "   - High unemployment rates may reflect areas with lower spending power.\n",
    "   - Poor health indicators could highlight areas needing healthcare services and accessible facilities.\n",
    "   - Housing tenure affects stability and service demandâareas with more rented accommodations may have higher population turnover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e83b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(merged_data.columns)\n",
    "#This is just a small sample of the number of potential variables you have available in the census\n",
    "# Using some ML techniques, you could include hundreds of these to make your geodemographics\n",
    "# more meaningful. For this academic exercise, only 386 variables will be loaded,\n",
    "# and then filtered to be included in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c226976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6834ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of selected variables for summary statistics\n",
    "selected_variables = [\n",
    "    'Population Density: Persons per square kilometre; measures: Value',\n",
    "    'Ethnic group: White',  \n",
    "    'Economic activity status: Economically active (excluding full-time students): Unemployed',\n",
    "    'Occupation (current): 2. Professional occupations',\n",
    "    'General health: Bad health',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a lot',\n",
    "    'Household deprivation: Household is deprived in two dimensions; measures: Value',\n",
    "    'Tenure of household: Private rented',\n",
    "    'Distance travelled to work: Works mainly from home',\n",
    "    'Highest level of qualification: Level 4 qualifications and above'\n",
    "]\n",
    "\n",
    "# Generate summary statistics for selected variables\n",
    "merged_data[selected_variables].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae74447",
   "metadata": {},
   "source": [
    "#### DEA Analysis - Visualising Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key DEA-related variables for visualization\n",
    "attributes_to_plot = [\n",
    "    'Economic activity status: Economically active (excluding full-time students): Unemployed',\n",
    "    'Household deprivation: Household is deprived in two dimensions; measures: Value',\n",
    "    'General health: Bad health',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a lot',\n",
    "    'Occupation (current): 2. Professional occupations',\n",
    "    'Highest level of qualification: Level 4 qualifications and above',\n",
    "    'Tenure of household: Owned',\n",
    "    'Distance travelled to work: Works mainly from home',\n",
    "    'Population Density: Persons per square kilometre; measures: Value'\n",
    "]\n",
    "\n",
    "# Create figure with 3x3 grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(14, 12))\n",
    "\n",
    "# Flatten the axes array to easily loop over it\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through attributes and assign plots to subplots\n",
    "for i, attribute in enumerate(attributes_to_plot):\n",
    "    sns.violinplot(x=merged_data[attribute], color=\"skyblue\", ax=axes[i])\n",
    "    axes[i].set_title(attribute, fontsize=10, rotation=10)  # Shortened & rotated titles\n",
    "    axes[i].set_xlabel('')  # Remove x-axis label\n",
    "    axes[i].set_ylabel('')\n",
    "\n",
    "# Adjust layout to fully remove title overlap\n",
    "plt.subplots_adjust(hspace=0.8, wspace=0.5)  # Increased spacing\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea028b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of attributes to plot (now 9 attributes)\n",
    "attributes_to_plot = [\n",
    "    'Economic activity status: Economically active (excluding full-time students): Unemployed',\n",
    "    'Household deprivation: Household is deprived in two dimensions; measures: Value',\n",
    "    'General health: Bad health',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a lot',\n",
    "    'Occupation (current): 2. Professional occupations',\n",
    "    'Highest level of qualification: Level 4 qualifications and above',\n",
    "    'Tenure of household: Owned',\n",
    "    'Distance travelled to work: Works mainly from home',\n",
    "    'Population Density: Persons per square kilometre; measures: Value'\n",
    "]\n",
    "\n",
    "# Create figure with 3x3 grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(14, 12))\n",
    "\n",
    "# Loop through attributes and assign plots to subplots\n",
    "for i, attribute in enumerate(attributes_to_plot):\n",
    "    row, col = divmod(i, 3)  # Determine subplot position\n",
    "    sns.histplot(merged_data[attribute], kde=True, bins=20, color=\"skyblue\", ax=axes[row, col])\n",
    "    axes[row, col].set_title(attribute, fontsize=7, wrap=True, rotation=10)  # Fix title overlap\n",
    "    axes[row, col].set_xlabel('')  # Remove x-axis label\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout to fully remove title overlap\n",
    "plt.subplots_adjust(hspace=0.8, wspace=0.5)  # Increased spacing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72521e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_to_plot = ['Economic activity status: Economically active (excluding full-time students): Unemployed',\n",
    "    'Household deprivation: Household is deprived in two dimensions; measures: Value',\n",
    "    'General health: Bad health',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a lot',]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, attribute in enumerate(attributes_to_plot, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.histplot(merged_data[attribute].astype(str), kde=True)\n",
    "    plt.title(attribute)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d46349",
   "metadata": {},
   "source": [
    "### Q5. Prepare, adjust or clean the dataset addressing any missing values or outliers that could distort the clustering results.\n",
    "\n",
    "**1. Socio-Demographics (7 variables)**\n",
    "- `Population Density: Persons per square kilometre; measures: Value` â **Indicates potential footfall for retail locations.**  \n",
    "- `Age: Aged 20 to 24 years` â **Captures younger consumers, important for fashion, entertainment, and fast food.**  \n",
    "- `Age: Aged 25 to 29 years` â **Captures working professionals with disposable income.**  \n",
    "- `Age: Aged 30 to 34 years` â **Represents key consumers for home goods, groceries, and family-related purchases.**  \n",
    "- `Age: Aged 65 years and over` â **Captures older consumers who may need accessible shopping options.**  \n",
    "- `Ethnic group: Total: All usual residents` â **Demographic diversity influences demand for specific products.**  \n",
    "- `Proficiency in English language: Main language is not English (English or Welsh in Wales): Cannot speak English well` â **Retailers may need multilingual signage, marketing, or staff.**  \n",
    "\n",
    "\n",
    "**2. Economic Activity & Occupation (8 variables)**\n",
    "- `Economic activity status: Economically active (excluding full-time students): In employment` â **Indicates the proportion of working residents who have disposable income.**  \n",
    "- `Economic activity status: Economically active (excluding full-time students): Unemployed` â **High unemployment may indicate lower retail spending.**  \n",
    "- `Economic activity status: Economically inactive: Retired` â **Captures areas with older consumers who may have different shopping habits.**  \n",
    "- `Occupation (current): 2. Professional occupations` â **Higher share of professionals indicates greater spending capacity.**  \n",
    "- `Occupation (current): 7. Sales and customer service occupations` â **Workers in these roles are key for retail employment and consumer trends.**  \n",
    "- `Occupation (current): 9. Elementary occupations` â **Lower-income workers may require budget-friendly retail options.**  \n",
    "- `Highest level of qualification: Level 4 qualifications and above` â **Higher education levels correlate with higher spending power.**  \n",
    "- `Distance travelled to work: Less than 2km` â **Indicates local workforce that supports nearby retail businesses.**  \n",
    "\n",
    "**3. Health Indicators (3 variables)**\n",
    "- `General health: Very good health` â **Healthier populations are likely to engage in leisure shopping and social activities.**  \n",
    "- `General health: Bad health` â **Higher rates of poor health may impact consumer mobility and retail accessibility needs.**  \n",
    "- `Disability: Disabled under the Equality Act: Day-to-day activities limited a lot` â **Indicates demand for accessible retail stores and services.**  \n",
    "\n",
    "**4. Housing & Living Conditions (7 variables)**\n",
    "- `Tenure of household: Owned` â **Homeownership often correlates with stable communities and higher retail spending.**  \n",
    "- `Tenure of household: Private rented` â **Higher rental areas may have more transient populations with different retail needs.**  \n",
    "- `Tenure of household: Social rented` â **Lower-income areas may require affordable retail options.**  \n",
    "- `Household deprivation: Household is deprived in two dimensions; measures: Value` â **Indicates economic disadvantage, influencing retail demand for budget stores.**  \n",
    "- `Household deprivation: Household is deprived in three dimensions; measures: Value` â **High deprivation areas may have lower retail spending power.**  \n",
    "- `Number of households: Number of households; measures: Value` â **Total household count helps estimate the size of the retail market.**  \n",
    "- `Distance travelled to work: Works mainly from home` â **Higher remote work levels can impact demand for local retail services.**  \n",
    "\n",
    "**Why These 25 Variables?**\n",
    "- **Consumer Demographics** â Age, ethnicity, language proficiency influence product demand.  \n",
    "- **Spending Power & Employment** â Economic activity, occupation, and education level impact disposable income.  \n",
    "- **Retail Accessibility & Footfall** â Population density, homeownership, and workforce commuting patterns affect store viability.  \n",
    "- **Health & Disability** â Affects shopping habits, accessibility requirements, and demand for health-related retail.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef97b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentages(dataframe, total_columns, value_columns):\n",
    "    \"\"\"\n",
    "    Calculate percentage values for selected variables based on corresponding totals.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The dataset containing the relevant variables.\n",
    "    - total_columns (list): List of total population columns corresponding to value columns.\n",
    "    - value_columns (list): List of specific value columns to be converted into percentages.\n",
    "\n",
    "    Returns:\n",
    "    - result_df (pd.DataFrame): DataFrame containing the percentage values.\n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    for total_col, value_col in zip(total_columns, value_columns):\n",
    "        percentage_col_name = f\"{value_col}_percentage\"\n",
    "\n",
    "        if total_col not in dataframe.columns or value_col not in dataframe.columns:\n",
    "            print(f\"Warning: '{total_col}' or '{value_col}' not found in DataFrame. Skipping...\")\n",
    "            continue  # Skips missing columns instead of raising an error\n",
    "\n",
    "        # Convert columns to numeric or NaN if errors occur\n",
    "        dataframe[value_col] = pd.to_numeric(dataframe[value_col], errors='coerce')\n",
    "        dataframe[total_col] = pd.to_numeric(dataframe[total_col], errors='coerce')\n",
    "        \n",
    "        result_df[percentage_col_name] = (dataframe[value_col] / dataframe[total_col]) * 100\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Updated total columns (Matching Dataset)\n",
    "total_cols = [\n",
    "    'Age: Total',\n",
    "    'Age: Total',\n",
    "    'Age: Total',\n",
    "    'Age: Total',\n",
    "    'Ethnic group: Total: All usual residents',\n",
    "    'Sex: All persons; measures: Value',\n",
    "    'Sex: All persons; measures: Value',\n",
    "    'Economic activity status: Total: All usual residents aged 16 years and over',\n",
    "    'Economic activity status: Total: All usual residents aged 16 years and over',\n",
    "    'Economic activity status: Total: All usual residents aged 16 years and over',\n",
    "    'Economic activity status: Total: All usual residents aged 16 years and over',\n",
    "    'Occupation (current): Total: All usual residents aged 16 years and over in employment the week before the census',\n",
    "    'Occupation (current): Total: All usual residents aged 16 years and over in employment the week before the census',\n",
    "    'Occupation (current): Total: All usual residents aged 16 years and over in employment the week before the census',\n",
    "    'General health: Total: All usual residents',\n",
    "    'General health: Total: All usual residents',\n",
    "    'Disability: Total: All usual residents',\n",
    "    'Disability: Total: All usual residents',\n",
    "    'Tenure of household: Total: All households',\n",
    "    'Tenure of household: Total: All households',\n",
    "    'Household deprivation: Total: All households; measures: Value',\n",
    "    'Household deprivation: Total: All households; measures: Value',\n",
    "    'Distance travelled to work: Total: All usual residents aged 16 years and over in employment the week before the census'\n",
    "]\n",
    "\n",
    "# Updated value columns (Matching Dataset)\n",
    "value_cols = [\n",
    "    'Age: Aged 20 to 24 years',\n",
    "    'Age: Aged 25 to 29 years',\n",
    "    'Age: Aged 30 to 34 years',\n",
    "    'Age: Aged 35 to 39 years',\n",
    "    'Ethnic group: White',\n",
    "    'Sex: Female; measures: Value',\n",
    "    'Sex: Male; measures: Value',\n",
    "    'Economic activity status: Economically active (excluding full-time students):In employment',\n",
    "    'Economic activity status: Economically active (excluding full-time students): Unemployed',\n",
    "    'Economic activity status: Economically inactive: Retired',\n",
    "    'Economic activity status: Economically inactive: Long-term sick or disabled',\n",
    "    'Occupation (current): 2. Professional occupations',\n",
    "    'Occupation (current): 7. Sales and customer service occupations',\n",
    "    'Occupation (current): 9. Elementary occupations',\n",
    "    'General health: Very good health',\n",
    "    'General health: Bad health',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a lot',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a little',\n",
    "    'Tenure of household: Owned',\n",
    "    'Tenure of household: Private rented',\n",
    "    'Household deprivation: Household is deprived in two dimensions; measures: Value',\n",
    "    'Household deprivation: Household is deprived in three dimensions; measures: Value',\n",
    "    'Distance travelled to work: Works mainly from home'\n",
    "]\n",
    "\n",
    "# Apply function to calculate percentages\n",
    "result_dataframe = calculate_percentages(merged_data, total_cols, value_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the resulting tables.\n",
    "concatenated_df = pd.concat([merged_data, result_dataframe], axis=1, ignore_index=False)\n",
    "concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24061c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72218d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(concatenated_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the attributes we need, we dont need the total for now.\n",
    "keep_cols= [\n",
    "    'OA_SA',\n",
    "    'geometry',\n",
    "    'Population Density: Persons per square kilometre; measures: Value',\n",
    "    'Age: Aged 20 to 24 years_percentage',\n",
    "    'Age: Aged 25 to 29 years_percentage',\n",
    "    'Age: Aged 30 to 34 years_percentage',\n",
    "    'Age: Aged 35 to 39 years_percentage',\n",
    "    'Ethnic group: White_percentage',\n",
    "    'Sex: Female; measures: Value_percentage',\n",
    "    'Sex: Male; measures: Value_percentage',\n",
    "    'Economic activity status: Economically active (excluding full-time students):In employment_percentage',\n",
    "    'Economic activity status: Economically active (excluding full-time students): Unemployed_percentage',\n",
    "    'Economic activity status: Economically inactive: Retired_percentage',\n",
    "    'Economic activity status: Economically inactive: Long-term sick or disabled_percentage',\n",
    "    'Occupation (current): 2. Professional occupations_percentage',\n",
    "    'Occupation (current): 7. Sales and customer service occupations_percentage',\n",
    "    'Occupation (current): 9. Elementary occupations_percentage',\n",
    "    'General health: Very good health_percentage',\n",
    "    'General health: Bad health_percentage',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a lot_percentage',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a little_percentage',\n",
    "    'Tenure of household: Owned_percentage',\n",
    "    'Tenure of household: Private rented_percentage',\n",
    "    'Household deprivation: Household is deprived in two dimensions; measures: Value_percentage',\n",
    "    'Household deprivation: Household is deprived in three dimensions; measures: Value_percentage',\n",
    "    'Distance travelled to work: Works mainly from home_percentage'\n",
    "]\n",
    "\n",
    "birmingham_census_data = concatenated_df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec707fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_census_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more easy manipulation we define short column names\n",
    "\n",
    "short_column_names = {\n",
    "    'OA_SA': 'output_areas',\n",
    "    'geometry': 'geometry',\n",
    "    'POPULATION': 'population',\n",
    "    'Population Density: Persons per square kilometre; measures: Value': 'pop_density',\n",
    "    'Age: Aged 20 to 24 years_percentage': 'age_20_24',\n",
    "    'Age: Aged 25 to 29 years_percentage': 'age_25_29',\n",
    "    'Age: Aged 30 to 34 years_percentage': 'age_30_34',\n",
    "    'Age: Aged 35 to 39 years_percentage': 'age_35_39',\n",
    "    'Ethnic group: White_percentage': 'eth_white',\n",
    "    'Sex: Female; measures: Value_percentage': 'female',\n",
    "    'Sex: Male; measures: Value_percentage': 'male',\n",
    "    'Economic activity status: Economically active (excluding full-time students):In employment_percentage': 'emp_active',\n",
    "    'Economic activity status: Economically active (excluding full-time students): Unemployed_percentage': 'emp_unemp',\n",
    "    'Economic activity status: Economically inactive: Retired_percentage': 'inactive_retired',\n",
    "    'Economic activity status: Economically inactive: Long-term sick or disabled_percentage': 'inactive_sick',\n",
    "    'Occupation (current): 2. Professional occupations_percentage': 'occ_prof',\n",
    "    'Occupation (current): 7. Sales and customer service occupations_percentage': 'occ_sales',\n",
    "    'Occupation (current): 9. Elementary occupations_percentage': 'occ_elem',\n",
    "    'General health: Very good health_percentage': 'health_very_good',\n",
    "    'General health: Bad health_percentage': 'health_bad',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a lot_percentage': 'disab_limited_lot',\n",
    "    'Disability: Disabled under the Equality Act: Day-to-day activities limited a little_percentage': 'disab_limited_little',\n",
    "    'Tenure of household: Owned_percentage': 'tenure_owned',\n",
    "    'Tenure of household: Private rented_percentage': 'tenure_rented',\n",
    "    'Household deprivation: Household is deprived in two dimensions; measures: Value_percentage': 'deprived_2dim',\n",
    "    'Household deprivation: Household is deprived in three dimensions; measures: Value_percentage': 'deprived_3dim',\n",
    "    'Distance travelled to work: Works mainly from home_percentage': 'work_home'\n",
    "}\n",
    "\n",
    "birmingham_census_data = birmingham_census_data.rename(columns=short_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c34897",
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_census_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca840d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_census_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d277a10f",
   "metadata": {},
   "source": [
    "### Q6. Include standardisation between areas and variables. Make an appropriate analysis and adjust the variable selection accordingly for any multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13833a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-score for each column, but we need to initially filter only the float attributes.\n",
    "# bcs you can't calculate that for the OA code.. :P\n",
    "\n",
    "numeric_columns = birmingham_census_data.select_dtypes(include='float64')\n",
    "z_score_df = (numeric_columns - numeric_columns.mean()) / numeric_columns.std(ddof=0)\n",
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = z_score_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(z_score_df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ea9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7 # We can adapt this based on waht we have in our data. Recall the subjetivity issue?\n",
    "# So if we include .8 then we wont be able to reduce any variables., so I took the threshold to 70%\n",
    "\n",
    "highly_correlated = (corr.abs() > threshold) & (corr.abs() < 1.0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(highly_correlated, cmap='coolwarm', cbar=False, annot=True)\n",
    "\n",
    "plt.title('Highly Correlated Variables')\n",
    "plt.show()\n",
    "\n",
    "# The plot will represent  BINARY table 0 for false( out of the threshold) and 1 for above the threshold.\n",
    "# but I also coloured so it is easier to use and cute :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b08884",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cff8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.drop(['female', 'work_home', 'disab_limited_lot'], axis=1, inplace=True)\n",
    "z_score_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_2 = z_score_df.corr()\n",
    "corr_2.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "highly_correlated_2 = (corr_2.abs() > threshold) & (corr_2.abs() < 1.0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(highly_correlated_2, cmap='coolwarm', cbar=False, annot=True)\n",
    "\n",
    "plt.title('New Highly Correlated Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_nan = z_score_df.isna().any().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"Oh no :( the DataFrame contains NaN values.\")\n",
    "else:\n",
    "    print(\"Wahoo! the dataFrame does not contain NaN values. I'm the best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.fillna(z_score_df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21681111",
   "metadata": {},
   "source": [
    "### Q7. Utilize the k-means clustering algorithm to create a classification based on the selected variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566637e",
   "metadata": {},
   "source": [
    "We will use the k-means clustering method, the same approach used to produce the Output Area Classifications you can find in multiple website in the UK. It is a top-down approach whereby the number of cluster groups is predefined. K-means is an iterative relocation algorithm based on an error sum of squares measure. The algorithm seeks to reduce the sum distance between each data point and their respective cluster centre. The diagram below illustrates the basic algorithm process of k-means clustering. \n",
    "\n",
    "It starts by randomly allocating seeds across a multidimensional space as defined by the variables, each case is then assigned to the nearest seed centroid. In other words, the cases are assigned into cluster groups based on the seed they are nearest to across the multiple variables.\n",
    "\n",
    "Following the first iteration, a new seed is created at the centroid of each of the clusters. Each case is then re-assigned to clusters based on the distance to the nearest of these new centroids. This process repeats iteratively until the centroid seed locations cannot be moved as an optimum solution has been reached (See Harris et al., 2005).\n",
    "\n",
    "The process of the k-means algorithm (taken from Lansley et al, 2015). The code is annotated below., but you can get all the parameter by running `?Kmeans`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92064f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "\n",
    "# When I first ran this code, I found that I kept getting different results. This is because, as discussed in class, \n",
    "# KMeans is a stocastic method. Therefore, I added a random_state and an arbitrary number so that the maps that you create will be the same. \n",
    "\n",
    "# KMeans with 10 clusters\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "z_score_df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea12a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels)\n",
    "# Ok, we clustered the data, but we subjectively defined the number of clusters, \n",
    "# and as you can see is one of the key parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff658f",
   "metadata": {},
   "source": [
    "### Q8. Define the optimum number of clusters (i.e., using the Elblow method). Experiment with different values of k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f44525",
   "metadata": {},
   "source": [
    "#### Testing using plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try doing the same plot as above but with different values \n",
    "# KMeans with 8 clusters\n",
    "kmeans = KMeans(n_clusters=8, random_state=9) # Trying 8\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "z_score_df['Cluster'] = kmeans.labels_\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=9) # Trying 6\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "z_score_df['Cluster'] = kmeans.labels_\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=9) # Trying 5\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "z_score_df['Cluster'] = kmeans.labels_\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024130a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=9) # Trying 4\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "z_score_df['Cluster'] = kmeans.labels_\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc803d5c",
   "metadata": {},
   "source": [
    "#### Elbow Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances = []\n",
    "\n",
    "K_range = range(1,15)\n",
    "\n",
    "for k in K_range:\n",
    " km = KMeans(n_clusters=k)\n",
    " km = km.fit(z_score_df)\n",
    " Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K_range, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95a743",
   "metadata": {},
   "source": [
    "The 'elbow' of the arm is around 4-5, which means we should try using a cluster number value close to 4-5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7399c",
   "metadata": {},
   "source": [
    "#### Between-Cluster Squares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ae2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow(dataframe, n):\n",
    "    kMeansVar = [KMeans(n_clusters=k).fit(dataframe.values) for k in range(1, n)] #making use of list comprehensions.\n",
    "    centroids = [X.cluster_centers_ for X in kMeansVar]\n",
    "    k_euclid = [cdist(dataframe.values, cent) for cent in centroids]\n",
    "    dist = [np.min(ke, axis=1) for ke in k_euclid]\n",
    "    wcss = [sum(d**2) for d in dist]\n",
    "    tss = sum(pdist(dataframe.values)**2)/dataframe.values.shape[0]\n",
    "    bss = tss - wcss\n",
    "    plt.plot(bss)\n",
    "    plt.show()\n",
    " \n",
    "elbow(z_score_df,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e268a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans with 6 clusters, after the validation with the Elbow method.\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "\n",
    "z_score_df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c06b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4dc53",
   "metadata": {},
   "source": [
    "EXPLORE WITH DIFFERENT k VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ff0f1",
   "metadata": {},
   "source": [
    "**What is the optimum number of clusters?**\n",
    "\n",
    "There is no right answer to this question. Even making judgements using some guidance on criteria involves a level of subjectivity. Your task is now to choose an appropriate number of clusters for your geodemographic classification.\n",
    "\n",
    "Aims of the cluster analysis:\n",
    "* Each cluster should be homogeneous as possible\n",
    "* Each cluster group should be distinct from the other groups\n",
    "* The groups should be as evenly sized as possible\n",
    "\n",
    "In addition, to each of these, we must also consider the compositions of the cluster groups. It is important that each of the characteristics of each cluster are distinguishable and relatable to real-life neighbourhoodtypes. \n",
    "\n",
    "Each cluster should be homogeneous as possible. Generally, the greater the number of clusters the closer the each case is to their cluster centroid on average. However, of course, with more groups the classification becomes more difficult to interpret and the differences between some groups may become more subtle. \n",
    "\n",
    "A measure we can use to check this is the within-cluster sum of squares which is the sum of the squared deviations from each observation to the cluster centroid. So larger sums indicate that the cluster is more dispersed and less homogenous. A plot of the within groups sum of squares by number of clusters extracted can help determine the appropriate number of clusters (k). The tip is to look for a bend in the plot similar to a scree test in factor analysis (called the elbow method).\n",
    "\n",
    "Each cluster group should be distinct from the other groups We can also measure how distinctive each of the clusters are in each model overall by looking at the between-cluster sum of squares. This value essentially measures how far apart clusters from different centres are. If the value is low then cases from different clusters will not be that distinctive. It is also important to observe the cluster centres to ensure that the compositions of each of the groups are logical and sufficiently unique.Having selected the number of clusters for the final model, below are two ways of visualising the fit of a k-means model, you may need to install the packages first (as described earlier). \n",
    "\n",
    "In the example 5 = k, and the data corresponds with all of the Output Areas. This Creates a bivariate plot visualising a partition (clustering) of the data. All observation are represented by points in the plot, using **principal components or multidimensional scaling**. Around each cluster, an ellipse is drawn.\n",
    "\n",
    "See here for the full documentation about the implementation of Kmeans and how you can validate your results:\n",
    "\n",
    "* https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html#sphx-glr-auto-examples-decomposition-plot-pca-iris-py\n",
    "* https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation\n",
    "* https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
    "* https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html#sphx-glr-auto-examples-cluster-plot-kmeans-assumptions-py\n",
    "\n",
    "**Using the two plots, is it possible to determine an appropriate number of groups?**\n",
    "\n",
    "There are also other methods for identifying statistically optimal groups such as **the average silhouette method** and **gap statistic method**.  \n",
    "\n",
    "The groups should be as evenly sized as possible. This is more of a rule of thumb for geodemographics. However, if a single cluster group comprises a large share of the data, then it is obviously undesirable for practitioners hoping to glean a better understanding of how the needs of neighbourhoods may vary. \n",
    "\n",
    "You might notice that your K-means has produced a small cluster group which has exaggerated cluster centre values for a small number of variables, this is not unusual when attempting to segment social  groups. \n",
    "\n",
    "There are two main ways to edit the size of the groups without manipulating the variables: \n",
    "\n",
    "* joining similar groups or\n",
    "* splitting large groups.\n",
    "\n",
    "If one cluster group is particularly dominant in size, you can force it into two groups by isolating the cases (statistical areas) from that group only and running a 2 group solution k-means. With only one group selected, you can run a k-means as you did before, but change the number of groups produced to 2. As only one group is selected, the output areas from other groups will be excluded from the analysis. If you are happy with the results you now need to combine the two new groups with the original group membership variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8de3fb",
   "metadata": {},
   "source": [
    "### Q9. Evaluate your cluster groups (e.g., using PCA) and interpret your cluster centres. Describe your results and repeat the process to adjust the variable selection and cluster groups to provide more meaningful results for your geodemographic goal. Interpret the characteristics of each cluster. What demographic patterns or similarities are prevalent within each group?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d182b",
   "metadata": {},
   "source": [
    "MAKE SURE TO ANS QUESTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e67914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code based on the example provided here: \n",
    "# https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html#sphx-glr-auto-examples-decomposition-plot-pca-iris-py\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "z_score_df['Cluster'] = clusters\n",
    "\n",
    "scaler = StandardScaler()\n",
    "stand_data_scaled = scaler.fit_transform(z_score_df)\n",
    "\n",
    "# PCA analysys.\n",
    "pca = PCA(n_components=2).fit(stand_data_scaled)\n",
    "pca_result = pca.transform(stand_data_scaled)\n",
    "\n",
    "#Percentage of variance explained by each of the selected components.\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(x=pca_result[:, 0], y=pca_result[:, 1], color=clusters,\n",
    "                 labels={'color': 'Cluster'},\n",
    "                 #title='Cluster Plot against 1st 2 Principal Components',\n",
    "                 opacity=0.7,\n",
    "                 width=800, \n",
    "                 height=800)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "print(f\"These two components explain {(variance_ratio.sum()*100):.2f}% of the point variability.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a static figure with the point variability included in the x/y-axis label.\n",
    "# So we can see what variability is provided by each component.\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "z_score_df['Cluster'] = clusters\n",
    "\n",
    "# Standardize the data for PCA\n",
    "scaler = StandardScaler()\n",
    "stand_data_scaled = scaler.fit_transform(z_score_df)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2).fit(stand_data_scaled)\n",
    "pca_result = pca.transform(stand_data_scaled)\n",
    "\n",
    "#Percentage of variance explained by each of the selected components.\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], hue=clusters, palette='viridis', s=50, alpha=0.7)\n",
    "plt.title('Cluster Plot against 1st 2 Principal Components')\n",
    "plt.xlabel(f'Principal Component 1 variation: {variance_ratio[0]*100:.2f}%')\n",
    "plt.ylabel(f'Principal Component 2 variation: {variance_ratio[1]*100:.2f}%')\n",
    "plt.legend(title='Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37f245",
   "metadata": {},
   "source": [
    "#### Interpreting Clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baba461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=z_score_df.columns)\n",
    "\n",
    "# Create a new DataFrame with cluster assignments and column names\n",
    "#result_df = pd.DataFrame({'Cluster': clusters, 'Column': z_score_df.columns})\n",
    "\n",
    "cluster_centers.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb0295",
   "metadata": {},
   "source": [
    "**Interpreting the cluster centres**\n",
    "\n",
    "Before any efforts are made to visualise the data, it is important you understand what it represents. The cluster centres (`kmeans.cluster_centers_`), indicates the coordinates of the centroid for each cluster group once the k-means had reached its optimum solution. It, therefore, is a good indicator of the average characteristics of each group based on the n variables that were included in the original model.\n",
    "\n",
    "We inputted **Z-score standardised data** into the model, therefore the cluster centres are still represented as Z-scores. Zero represents the mean for each variable and values above or below indicate the number of standard deviations away from the average. The values can, therefore, be used to very easily understand how unique each group is relative to the whole sample (in this case, all of the pop_data you inputted).\n",
    "\n",
    "**What if we print the cluster centrers?** --**Is it immediately clear what your groups represent?**\n",
    "\n",
    "It might be easier to create charts to visualise the characteristics of each cluster group. In the example below we will create radial plots, using the first group as our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the centre values for Cluster 0 (the first cluster)\n",
    "first_row_centers = cluster_centers.iloc[0, :]\n",
    "\n",
    "# Step 2: Count the number of features (i.e., variables used in clustering)\n",
    "num_features = len(first_row_centers)\n",
    "\n",
    "# Step 3: Generate evenly spaced angles (in radians) for each feature around a circle\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "# Step 4: Create a polar plot using matplotlib\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(10, 6))\n",
    "\n",
    "# Step 5: Plot the cluster centre values as a line on the radar chart\n",
    "ax.plot(theta, first_row_centers, linewidth=2, color='blue', marker='o', label='Centres')\n",
    "\n",
    "# Step 6: Plot a red baseline representing the origin (zero line)\n",
    "ax.plot(theta, np.zeros_like(first_row_centers), color='red', linestyle='--', label='Average')\n",
    "\n",
    "# Step 7: Label each spoke of the radar chart with the corresponding variable name\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns, rotation=45, ha='right', fontsize=6)\n",
    "\n",
    "# Optional: Add a legend and tidy layout\n",
    "plt.title(\"Cluster 0 Profile Across Census Variables\", fontsize=12, pad=20)\n",
    "\n",
    "# Step 8: Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec595e14",
   "metadata": {},
   "source": [
    "INSERT WHERE HIGH OR LOW COMPARED TO AVERAGE AND GROUP CLUSTER TITLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36779ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the centre values for Cluster 1 (the first cluster)\n",
    "second_row_centers = cluster_centers.iloc[1, :] \n",
    "\n",
    "# Step 2: Count the number of features (i.e., variables used in clustering)\n",
    "num_features = len(second_row_centers)\n",
    "\n",
    "# Step 3: Generate evenly spaced angles (in radians) for each feature around a circle\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "# Step 4: Create a polar plot using matplotlib\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(10, 6))\n",
    "\n",
    "# Step 5: Plot the cluster centre values as a line on the radar chart\n",
    "ax.plot(theta, second_row_centers, linewidth=2, color='blue', marker='o', label='Centers')\n",
    "\n",
    "# Step 6: Plot a red baseline representing the origin (zero line)\n",
    "ax.plot(theta, np.zeros_like(second_row_centers), color='red', linestyle='--', label='Average')\n",
    "\n",
    "# Step 7: Label each spoke of the radar chart with the corresponding variable name\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns, rotation=45, ha='right', fontsize=8)\n",
    "\n",
    "# Optional: Add a legend and tidy layout\n",
    "plt.title(\"Cluster 1 Profile Across Census Variables\", fontsize=12, pad=20)\n",
    "\n",
    "# Step 8: Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263b477",
   "metadata": {},
   "source": [
    "INSERT WHERE HIGH OR LOW COMPARED TO AVERAGE AND GROUP CLUSTER TITLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb60c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the centre values for Cluster 2 (the first cluster)\n",
    "third_row_centers = cluster_centers.iloc[2, :] \n",
    "\n",
    "# Step 2: Count the number of features (i.e., variables used in clustering)\n",
    "num_features = len(third_row_centers)\n",
    "\n",
    "# Step 3: Generate evenly spaced angles (in radians) for each feature around a circle\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "# Step 4: Create a polar plot using matplotlib\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(10, 6))\n",
    "\n",
    "# Step 5: Plot the cluster centre values as a line on the radar chart\n",
    "ax.plot(theta, third_row_centers, linewidth=2, color='blue', marker='o', label='Centers')\n",
    "\n",
    "# Step 6: Plot a red baseline representing the origin (zero line)\n",
    "ax.plot(theta, np.zeros_like(third_row_centers), color='red', linestyle='--', label='Average')\n",
    "\n",
    "# Step 7: Label each spoke of the radar chart with the corresponding variable name\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns, rotation=45, ha='right', fontsize=8)\n",
    "\n",
    "# Optional: Add a legend and tidy layout\n",
    "plt.title(\"Cluster 2 Profile Across Census Variables\", fontsize=12, pad=20)\n",
    "\n",
    "# Step 8: Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd167d",
   "metadata": {},
   "source": [
    "INSERT WHERE HIGH OR LOW COMPARED TO AVERAGE AND GROUP CLUSTER TITLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the centre values for Cluster 3 (the first cluster)\n",
    "fourth_row_centers = cluster_centers.iloc[3, :] \n",
    "\n",
    "# Step 2: Count the number of features (i.e., variables used in clustering)\n",
    "num_features = len(fourth_row_centers)\n",
    "\n",
    "# Step 3: Generate evenly spaced angles (in radians) for each feature around a circle\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "# Step 4: Create a polar plot using matplotlib\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(10, 6))\n",
    "\n",
    "# Step 5: Plot the cluster centre values as a line on the radar chart\n",
    "ax.plot(theta, fourth_row_centers, linewidth=2, color='blue', marker='o', label='Centers')\n",
    "\n",
    "# Step 6: Plot a red baseline representing the origin (zero line)\n",
    "ax.plot(theta, np.zeros_like(fourth_row_centers), color='red', linestyle='--', label='Average')\n",
    "\n",
    "# Step 7: Label each spoke of the radar chart with the corresponding variable name\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns, rotation=45, ha='right', fontsize=8)\n",
    "\n",
    "# Optional: Add a legend and tidy layout\n",
    "plt.title(\"Cluster 3 Profile Across Census Variables\", fontsize=12, pad=20)\n",
    "\n",
    "# Step 8: Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca8d02",
   "metadata": {},
   "source": [
    "INSERT WHERE HIGH OR LOW COMPARED TO AVERAGE AND GROUP CLUSTER TITLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the centre values for Cluster 4 (the first cluster)\n",
    "fifth_row_centers = cluster_centers.iloc[4, :] \n",
    "\n",
    "# Step 2: Count the number of features (i.e., variables used in clustering)\n",
    "num_features = len(fifth_row_centers)\n",
    "\n",
    "# Step 3: Generate evenly spaced angles (in radians) for each feature around a circle\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "# Step 4: Create a polar plot using matplotlib\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(10, 6))\n",
    "\n",
    "# Step 5: Plot the cluster centre values as a line on the radar chart\n",
    "ax.plot(theta, fifth_row_centers, linewidth=2, color='blue', marker='o', label='Centers')\n",
    "\n",
    "# Step 6: Plot a red baseline representing the origin (zero line)\n",
    "ax.plot(theta, np.zeros_like(fifth_row_centers), color='red', linestyle='--', label='Average')\n",
    "\n",
    "# Step 7: Label each spoke of the radar chart with the corresponding variable name\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns, rotation=45, ha='right', fontsize=8)\n",
    "\n",
    "# Optional: Add a legend and tidy layout\n",
    "plt.title(\"Cluster 4 Profile Across Census Variables\", fontsize=12, pad=20)\n",
    "\n",
    "# Step 8: Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1061c",
   "metadata": {},
   "source": [
    "INSERT WHERE HIGH OR LOW COMPARED TO AVERAGE AND GROUP CLUSTER TITLE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d872fd",
   "metadata": {},
   "source": [
    "### Q10. Map the final cluster groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(z_score_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dafd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.drop([\n",
    " 'pop_density',\n",
    " 'age_20_24',\n",
    " 'age_25_29',\n",
    " 'age_30_34',\n",
    " 'age_35_39',\n",
    " 'eth_white',\n",
    " 'male',\n",
    " 'emp_active',\n",
    " 'emp_unemp',\n",
    " 'inactive_retired',\n",
    " 'inactive_sick',\n",
    " 'occ_prof',\n",
    " 'occ_sales',\n",
    " 'occ_elem',\n",
    " 'health_very_good',\n",
    " 'health_bad',\n",
    " 'disab_limited_little',\n",
    " 'tenure_owned',\n",
    " 'tenure_rented',\n",
    " 'deprived_2dim',\n",
    " 'deprived_3dim'], axis=1, inplace=True)\n",
    "z_score_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the resulting tables.\n",
    "final_df = pd.concat([birmingham_census_data, z_score_df], axis=1, ignore_index=False)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5afcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.explore(column='Cluster', cmap='Set1', tiles='CartoDB positron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f343b2f0",
   "metadata": {},
   "source": [
    "### Q11. Finish the analysis by naming the final clusters and plotting a final map that includes the census values and the provided names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column(x): \n",
    "    x = str(x)  # Convert integer to string\n",
    "    x = x.replace(\"0\", \"Title\") # Replacing for the categories defined earlier. \n",
    "    x = x.replace(\"1\", \"Title\")\n",
    "    x = x.replace(\"2\", \"Title\")\n",
    "    x = x.replace(\"3\", \"Title\")\n",
    "    x = x.replace(\"4\", \"Title\")\n",
    "    return x\n",
    "\n",
    "final_df['Cluster'] = final_df['Cluster'].apply(rename_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.explore(column='Cluster', cmap='Set1', tiles='CartoDB positron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c83124",
   "metadata": {},
   "source": [
    "### Q12. Finally, acknowledge the subjective nature of classification and make analytical decisions to produce an optimum classification for your specific purpose. Reflect on the challenges and insights gained during the classification process. Ensure you document your analytical decisions and the rationale behind any important decision. Once your geodemographics are constructed, describe the potential use cases for the geodemographic classification you have built based on your initial goal.\n",
    "\n",
    "Finally, acknowledge the subjective nature of classification and make analytical decisions to produce an optimum classification for your specific purpose. Reflect on the challenges and insights gained during the classification process. Ensure you document your analytical decisions and the rationale behind any important decision. Once your geodemographics are constructed, describe the potential use cases for the geodemographic classification you have built based on your initial goal\n",
    "\n",
    "#### Challenges and Insights \n",
    "\n",
    "To start with the challenges, defining the characteristics of a cluster was difficult to assess. The word choice and the most important factors to identity cluster by seemed to be reductive in light of all the data analysed. Moreover, by creating these categories, I felt that residents who were in the minority within these OAs were not accounted for. \n",
    "Applying the categories to a more limited subset of the census data (ie a certain age range, etc.) made it difficult to determine which of the population subgroup defnitions were appropriate. Likely, ground-truthing and qualitative interviews would need to be conducted to verify the geodemographic data presented. \n",
    "\n",
    "Another issue is the stocastic nature of KMeans itself. This means that everytime the method is run, there is a slightly different output, which makes the data hard to reproduce and use for further analysis. I attempted to rectify this by specifying the random_state number, but more deterministic modelling techniques might be appropriate if this were to be actually used to inform a company or social service provider. \n",
    "\n",
    "In term of insights, there are clear spatially distributed patterns of suburban achievers on the outskirts of Birmingham. Commuters with families also made up a large marjority of the OAs, but despite this, there are clear areas that are predominantly younger students and comfortable cosmopolitans. \n",
    "\n",
    "#### Potential Use Cases \n",
    "In choosing the variables to make this classification, I had in mind a younger demographic, particularly for use by an advertising agency. This informed my selection of the age demographic and the availability of transportation. For example, any advertisements for a cologne or perfume brand would likely want to know the education level and employment type of the people in certain neighborhoods; this would inform the word choice used in advertising. Additionally, knowing whether people are commuters or not will inform the placement of advertisements. To advertise a cologne/perfume to the Suburban Achievers cluster, agencies might decide to invest more in large billboards by roadways. On the other hand, if the target audience are students, understanding their employment type and their spatial distrubution would make for more effective ads and inform their pricing calculations. This can aid the company or brand by providing an understanding of who their consumers are and what values they might share. \n",
    "\n",
    "Another potential use case for this is for public health interventions. For example, if there is a public health intervention on sexual health and STI testing, understanding the employment type, language preference/understanding, and income would be very relevant factors for targeting certain interventions and for defining the promotional material used. Interventions on public health issues would also be different for families versus single persons, and might need to reflect employment type and whether the population is a student or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6440b-3a4f-4a99-a807-19a4d1ef1aa6",
   "metadata": {},
   "source": [
    "# Lab No 7: Spatial Microsimulation (3 Challenges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab613243-ba52-476b-b88c-ffddadbdb7e8",
   "metadata": {},
   "source": [
    "## Challenge 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169811b-991b-4e6d-8a52-57148eec2252",
   "metadata": {},
   "source": [
    "## Challenge 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a71392-c3d1-4a33-8366-f11af8ad5f02",
   "metadata": {},
   "source": [
    "## Challenge 3: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db6c2e",
   "metadata": {},
   "source": [
    "# Final Remarks (limitations, barriers, and any additional comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
